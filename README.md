# ğŸ›¡ï¸ FAKE-GUARD

### Fake Social Media Account Detection Dashboard

FAKE-GUARD is a **cybersecurity analytics dashboard** designed to identify and assess **fake social media accounts** using **behavioral risk analysis**.
The system is built as a **central monitoring tool** for agencies to quickly evaluate suspicious accounts and take action.

---

## ğŸ“Œ Problem Statement

Fake social media accounts are widely used to:

* Spread misinformation
* Conduct social engineering
* Target security organizations

Manual identification is slow and ineffective at scale.
FAKE-GUARD provides an **automated, explainable, and scalable solution**.

---

## ğŸ¯ Solution Overview

FAKE-GUARD works in **two layers**:

### 1ï¸âƒ£ Batch Analysis (Offline ML Output)

* Uses precomputed ML-based risk scores
* Analyzes historical account behavior
* Displays risk level and recommended action

### 2ï¸âƒ£ Dynamic Risk Assessment (Rule-Based)

* Real-time risk estimation using behavioral rules
* No ML model required at runtime
* Suitable for quick analyst investigation

---

## ğŸ§  Features Used (Behavioral Inputs)

The system is **privacy-preserving** and uses only behavioral indicators:

* **Total Posts** â€“ Activity intensity
* **Average Text Length** â€“ Message structure
* **Duplicate Ratio** â€“ Repetitive behavior

Raw message content is **never stored or analyzed**.

---

## ğŸ—‚ï¸ Dataset Description

The original dataset contains **post-level data**:

* `fake_account.csv`
* `legitimate_account.csv`

Each record represents a **single post** with:

* `user_id`
* `text`

These were **aggregated into account-level features** during preprocessing.

---

## âš™ï¸ Data Preprocessing & Feature Engineering

Steps performed:

1. Data cleaning and encoding handling
2. Labeling fake vs legitimate accounts
3. Aggregating post-level data â†’ account-level behavior
4. Feature extraction:

   * total_posts
   * avg_text_length
   * duplicate_ratio

---

## ğŸ“Š Risk Scoring Logic

To ensure clear differentiation, FAKE-GUARD applies:

* Log scaling
* Feature amplification
* Percentile-based normalization

This produces a **0â€“100 operational risk score**:

* **High Risk** â†’ Immediate action
* **Medium Risk** â†’ Manual review
* **Low Risk** â†’ No action

---

## ğŸ–¥ï¸ User Interface

The dashboard includes:

* KPI cards (High / Medium / Low risk counts)
* Account selection panel
* Risk score visualization
* Behavioral indicators
* Recommended action
* Top high-risk accounts table

Designed to resemble a **real security operations dashboard**.

---

## ğŸš€ Deployment

The project is deployed using **Streamlit Community Cloud**.

### Files required:

```
app.py
fake_guard_results.csv
requirements.txt
```

### `requirements.txt`

```
streamlit
pandas
numpy
```

---

## ğŸ› ï¸ How to Run Locally

```bash
pip install streamlit pandas numpy
streamlit run app.py
```

---

## ğŸ” Why This Approach Works

* Platform-agnostic (Facebook, Instagram, X, etc.)
* Scalable and fast
* Privacy-preserving
* Explainable decisions
* Real-world cybersecurity alignment


## ğŸ¤ One-Line Summary (For Judges)

> â€œFAKE-GUARD converts social media behavior into actionable intelligence for rapid fake account detection.â€

## ğŸ“Œ Project Status

âœ” Data preprocessing completed
âœ” Feature engineering completed
âœ” Risk scoring implemented
âœ” Dashboard deployed
âœ” Ready for evaluation
